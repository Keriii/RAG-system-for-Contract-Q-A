{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# from langchain_community.document_loaders import pypdf\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Weaviate\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from typing import List,Union\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')  # Adjust the path accordingly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splitters import *\n",
    "from retrivers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing an appropriate chunking and text splitter mechanism is crutial for the performance of the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# Lets start by loading the document \n",
    "loader = PyPDFLoader('../data/RobinsonAdvisory.pdf')\n",
    "contract = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_doc = RecursiveSplitter(contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_doc = characterSplitter(contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kerod/Desktop/week_11/RAG-system-for-Contract-Q-A/week_11/lib/python3.10/site-packages/pydantic/main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    }
   ],
   "source": [
    "semantic_doc = SemanticSplitter(contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_docx_file_path = \"../data/Robinson Q&A.docx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Weaviate\n",
    "import docx\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import weaviate\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from weaviate.embedded import EmbeddedOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorStore(doc):\n",
    "    client = weaviate.Client(embedded_options=EmbeddedOptions)\n",
    "    vectorstore = Weaviate.from_documents(client =  client,\n",
    "                                        documents= doc,\n",
    "                                        embedding=OpenAIEmbeddings(),\n",
    "                                        by_text = False)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kerod/Desktop/week_11/RAG-system-for-Contract-Q-A/week_11/lib/python3.10/site-packages/weaviate/warnings.py:158: DeprecationWarning: Dep016: You are using the Weaviate v3 client, which is deprecated.\n",
      "            Consider upgrading to the new and improved v4 client instead!\n",
      "            See here for usage: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 8079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kerod/Desktop/week_11/RAG-system-for-Contract-Q-A/week_11/lib/python3.10/site-packages/pydantic/main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 8079\n",
      "embedded weaviate is already listening on port 8079\n"
     ]
    }
   ],
   "source": [
    "chara_vS = create_vectorStore(character_doc)\n",
    "recur_vs = create_vectorStore(recursive_doc)\n",
    "sem_vs = create_vectorStore(semantic_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_retriver = chara_vS.as_retriever()\n",
    "recur_retriver = recur_vs.as_retriever()\n",
    "sem_retriver = sem_vs.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough\n",
    ")\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_chain(retriever):\n",
    "    # Define LLM\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "    # Define prompt template\n",
    "    prompt_template = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "\n",
    "    retrieval = RunnableParallel(\n",
    "        {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    )\n",
    "\n",
    "    chain = retrieval | prompt | llm | StrOutputParser()\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_chain = llm_chain(char_retriver)\n",
    "recur_chain = llm_chain(recur_retriver)\n",
    "sem_chain = llm_chain(sem_retriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "def extract_questions_answers(docx_file):\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    doc = Document(docx_file)\n",
    "\n",
    "    # Iterate through paragraphs\n",
    "    for i in range(len(doc.paragraphs)):\n",
    "        text = doc.paragraphs[i].text.strip()\n",
    "        # Alternate paragraphs are questions and answers\n",
    "        if text.startswith(\"Q\"):\n",
    "            question = text.split(\": \", 1)[-1].strip()\n",
    "            questions.append(question)\n",
    "        elif text.startswith(\"A\"):\n",
    "            answer = text.split(\": \", 1)[-1].strip()\n",
    "            answers.append(answer)\n",
    "            \n",
    "            i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "        \n",
    "        # if i % 2 == 0:\n",
    "        #     questions.append(doc.paragraphs[i].text)\n",
    "        # else:\n",
    "        #     answers.append(doc.paragraphs[i].text)\n",
    "\n",
    "    return questions, answers\n",
    "\n",
    "questions, ground_truth = extract_questions_answers(qa_docx_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m answers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[0;32m----> 6\u001b[0m     contexts\u001b[38;5;241m.\u001b[39mappend([docs\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m docs \u001b[38;5;129;01min\u001b[39;00m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39mget_relevant_documents(question)])\n\u001b[1;32m      7\u001b[0m     answers\u001b[38;5;241m.\u001b[39mappend(chain\u001b[38;5;241m.\u001b[39minvoke(question))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "ground_truths = [[x] for x in ground_truth]\n",
    "\n",
    "contexts = []\n",
    "answers = []\n",
    "for question in questions:\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(question)])\n",
    "    answers.append(chain.invoke(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Preparing the dataset\n",
    "data = {\n",
    "            \"question\": questions,\n",
    "            \"answer\": answers,\n",
    "            \"contexts\": contexts,\n",
    "            \"ground_truth\": ground_truth\n",
    "        }\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=dataset, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    ")\n",
    "\n",
    "df = result.to_pandas()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
